include "serialization"

akka {
    log-dead-letters = 1
    log-dead-letters-during-shutdown = false
    event-handlers = ["akka.event.slf4j.Slf4jEventHandler"]
    loglevel = DEBUG
    loggers = ["akka.event.slf4j.Slf4jLogger"]

    extensions = [
        "akka.contrib.pattern.DistributedPubSubExtension",
        "akka.contrib.pattern.ClusterReceptionistExtension"
    ]

    debug {
        lifecycle = on
        receive = on
    }

    mailer-dispatcher {
        type = "Dispatcher"
        executor = "thread-pool-executor"
        throughput = 20
        thread-pool-executor {
          core-pool-size-min = 4
          core-pool-size-factor = 2.0
          core-pool-size-max = 20
          #core-pool-size-max = 16
        }
    }

    cluster-dispatcher {
        type = "Dispatcher"
        executor = "fork-join-executor"
        throughput = 50
        fork-join-executor {
            parallelism-min = 2
            parallelism-factor = 2.0
            parallelism-max = 16
        }
    }

    actor {
        provider = "akka.cluster.ClusterActorRefProvider"
        serialize-messages = off # this will be off in production

        deployment {
            /mailer {
                router = round-robin-pool
                nr-of-instances = 10
                depatcher = "akka.mailer-dispatcher"
            }
            "/mailer/*" {
                depatcher = "akka.mailer-dispatcher"
            }
        }
    }

    remote {
        enabled-transports = ["akka.remote.netty.tcp"]
        netty.tcp {
           #hostname = "192.168.0.103"
           #port = 0
           maximum-frame-size = 512000b
           receive-buffer-size = 1024000b
           send-buffer-size = 1024000b
        }
    }

    persistence {
        view.auto-update-interval = 1000ms

        # we need event publishing for tests
        # publish-confirmations = on
        publish-plugin-commands = off

        # disable leveldb (default store impl)
        journal.leveldb.native = off

        encryption-settings = "import akka.persistence.hbase.common.EncryptionConfig;new EncryptionConfig(keyMap = Map(1 -> \"thisIsASecretKey\".getBytes))"

        replay-gap-retry = 3

        export-sequence {
          enable-export = false
          processor-id = "p_m_btccny"
          #file = "/tmp/market_view.txt"
          file = "/tmp/market_processor.txt"
        }
    }

    contrib.persistence.mongodb.mongo {
        db = "coinex"
        journal-collection = "events"
        journal-index = "messages_index"
        snaps-collection = "snapshots"
        snaps-index = "snapshots_index"
    }


    cluster {
        use-dispatcher = "akka.cluster-dispatcher"
        auto-down-unreachable-after = 2s
        #roles = [
            #"market_processor_btc_rmb",
            #"market_depth_view_btc_rmb",
            #"user_processor",
            #"account_processor",
            #"marke_update_processor",
            #"user_view",
            #"account_view",
            #"candle_data_view"
        #]
        #role {
            # user_processor.min-nr-of-members = 1
            # account_processor.min-nr-of-members = 1
            # market_processor_btc_rmb.min-nr-of-members = 1
            # marke_update_processor.min-nr-of-members = 1
        #}
        #seed-nodes = [
        #   "akka.tcp://coinex@192.168.0.103:25551"
        #]
    }

    exchange {
        secret = ";e3Tfq&-D+/PaFYTf1N2Uh.Y@j9d`<yY~c^eA%T~h:zA|[nm^*wN^lO?$qb^&"
	mailer.mandrill-api-key = "YqW5g_wxhP0rSwV59-QbOQ"
        monitor.http-port = 25550
        account-config-path = "account.scala"
    }
}

hbase-journal {
  table = "messages"
  family = "a"
  # has been hardcode to 18, this configure will be ignore
  # partition.count= 18
  scan-batch-size = 20
  client-flush-interval = 0
  publish-testing-events = off

  # For HBase sync
  plugin-dispatcher = "akka-hbase-persistence-dispatcher"

  # Original config
  replay-dispatcher = "default-replay-dispatcher"

  class = "akka.persistence.hbase.journal.HBaseAsyncWriteJournal"
  hbase {
    zookeeper.quorum = "hadoop:2181"
  }
}

hadoop-snapshot-store {
  hdfs-default-name = "hdfs://hadoop:54310"
  snapshot-dir = "/snapshot/"
  publish-testing-events = off
  class = "akka.persistence.hbase.snapshot.HadoopSnapshotStore"

  # For HBase sync
  plugin-dispatcher = "akka-hbase-persistence-dispatcher"

  # Original config
  replay-dispatcher = "default-replay-dispatcher"

  impl = "akka.persistence.hbase.snapshot.HdfsSnapshotter"

  # HBaseSnapshotter config
  #impl = "akka.persistence.hbase.snapshot.HBaseSnapshotter"
  #table = "snapshot"
  #family = "a"
  #client-flush-interval = 0
  #hbase {
  #  cluster.distributed = false
  #  zookeeper.quorum = "hadoop:2181"
  #}
}

akka-hbase-persistence-dispatcher {
  type = Dispatcher
  executor = "thread-pool-executor"
  thread-pool-executor {
    core-pool-size-min = 2
    core-pool-size-factor = 2.0
    core-pool-size-max = 10
  }
  throughput = 100
}

default-replay-dispatcher {
    type = Dispatcher
    executor = "fork-join-executor"
    fork-join-executor {
        parallelism-min = 2
        parallelism-max = 8
    }
}
