include "serialization"

akka {
    log-dead-letters = 0
    log-dead-letters-during-shutdown = false
    event-handlers = ["akka.event.slf4j.Slf4jEventHandler"]
    loglevel = INFO
    loggers = ["akka.event.slf4j.Slf4jLogger"]

    extensions = [
        "akka.contrib.pattern.DistributedPubSubExtension",
        "akka.contrib.pattern.ClusterReceptionistExtension"
    ]

    debug {
        lifecycle = off
        receive = off
    }

    mailer-dispatcher {
        type = "Dispatcher"
        executor = "thread-pool-executor"
        throughput = 20
        thread-pool-executor {
          core-pool-size-min = 4
          core-pool-size-factor = 2.0
          core-pool-size-max = 16
        }
    }

    cluster-dispatcher {
        type = "Dispatcher"
        executor = "fork-join-executor"
        throughput = 50
        fork-join-executor {
            parallelism-min = 2
            parallelism-factor = 2.0
            parallelism-max = 16
        }
    }

    actor {
        provider = "akka.cluster.ClusterActorRefProvider"
        serialize-messages = off # this will be off in production

        deployment {
            /mailer {
                router = round-robin-pool
                nr-of-instances = 10
                depatcher = "akka.mailer-dispatcher"
            }
            "/mailer/*" {
                depatcher = "akka.mailer-dispatcher"
            }
        }
    }

    remote {
        enabled-transports = ["akka.remote.netty.tcp"]
        netty.tcp {
           hostname = "localhost"
           port = 25549
        }
    }

    persistence {
        view.auto-update-interval = 100ms

        journal.plugin = "akka-contrib-mongodb-persistence-journal"
        #journal.plugin = "hbase-journal"

        snapshot-store.plugin = "akka-contrib-mongodb-persistence-snapshot"
        #snapshot-store.plugin = "hadoop-snapshot-store"

        # we need event publishing for tests
        # publish-confirmations = on
        publish-plugin-commands = off

        # disable leveldb (default store impl)
        journal.leveldb.native = off

        encryption-settings = "import akka.persistence.hbase.common.EncryptionConfig;new EncryptionConfig(keyMap = Map(1 -> \"thisIsASecretKey\".getBytes))"

        replay-gap-retry = 3

        export-sequence {
          enable-export = false
          processor-id = "p_m_btccny"
          #file = "/tmp/market_view.txt"
          file = "/tmp/market_processor.txt"
        }
    }

    contrib.persistence.mongodb.mongo {
        urls = ["localhost:52345"]
        db = "integration_testing_coinex"
        journal-collection = "events"
        journal-index = "messages_index"
        snaps-collection = "snapshots"
        snaps-index = "snapshots_index"
    }


    cluster {
        use-dispatcher = "akka.cluster-dispatcher"
        auto-down-unreachable-after = 2s
        seed-nodes = [
           "akka.tcp://coinex@localhost:25549"
        ]
    }

    exchange {
        secret = ";e3Tfq&-D+/PaFYTf1N2Uh.Y@j9d`<yY~c^eA%T~h:zA|[nm^*wN^lO?$qb^&"
        mailer.mandrill-api-key = "YqW5g_wxhP0rSwV59-QbOQ"
        monitor.http-port = 25550
        mongo-uri-for-readers = "mongodb://localhost:52345/integration_testing_coinex_views"
        mongo-uri-for-events = "mongodb://localhost:52345/integration_testing_coinex_export"
        account-config-path = "integration_account.scala"
        bitway-path = "integration_bitway.scala"
        opendata-path = "integration_open_data_config.scala"
        transfer-path = "integration_account_transfer.scala"
    }
}

hbase-journal {
  table = "messages"
  family = "a"
  # has been hardcode to 18, this configure will be ignore
  # partition.count= 18
  scan-batch-size = 20
  client-flush-interval = 0
  publish-testing-events = off

  # For HBase sync
  plugin-dispatcher = "akka-hbase-persistence-dispatcher"

  # Original config
  replay-dispatcher = "default-replay-dispatcher"

  class = "akka.persistence.hbase.journal.HBaseAsyncWriteJournal"
  hbase {
    cluster.distributed = false
    zookeeper.quorum = "hadoop:2181"
  }
}

hadoop-snapshot-store {
  hdfs-default-name = "hdfs://hadoop:54310"
  snapshot-dir = "/snapshot/"
  publish-testing-events = off
  class = "akka.persistence.hbase.snapshot.HadoopSnapshotStore"

  # For HBase sync
  plugin-dispatcher = "akka-hbase-persistence-dispatcher"

  # Original config
  replay-dispatcher = "default-replay-dispatcher"

  impl = "akka.persistence.hbase.snapshot.HdfsSnapshotter"

  # HBaseSnapshotter config
  #impl = "akka.persistence.hbase.snapshot.HBaseSnapshotter"
  #table = "snapshot"
  #family = "a"
  #client-flush-interval = 0
  #hbase {
  #  cluster.distributed = false
  #  zookeeper.quorum = "hadoop:2181"
  #}
}

akka-hbase-persistence-dispatcher {
  type = Dispatcher
  executor = "thread-pool-executor"
  thread-pool-executor {
    core-pool-size-min = 2
    core-pool-size-factor = 2.0
    core-pool-size-max = 10
  }
  throughput = 100
}

default-replay-dispatcher {
    type = Dispatcher
    executor = "fork-join-executor"
    fork-join-executor {
        parallelism-min = 2
        parallelism-max = 8
    }
}
